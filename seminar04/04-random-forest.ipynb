{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Ensembling \n",
    "\n",
    "![ensemble_idea][1]\n",
    "\n",
    "[1]: weak-classifiers.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digits Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_digits(n_class=10, return_X_y=True)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X.shape[:1] == y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = np.random.randint(0, y.size)\n",
    "\n",
    "plt.imshow(X[ix].reshape(8, 8))\n",
    "plt.title(f'digit {y[ix]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Features\n",
    "\n",
    "We need many `stupid` classifiers which make `errors in different parts` of the feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trees = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an array to store probability predictions for different runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas = np.empty((n_trees, ) + y_test.shape + (10, ))\n",
    "y_probas.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train `n_trees` decision tree classifiers and save class probabilities to `y_probas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, state in enumerate(range(n_trees)):\n",
    "    model = DecisionTreeClassifier(max_features=4, max_depth=2, random_state=state)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_probas[i] = model.predict_proba(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    feat_index, = np.nonzero(model.feature_importances_)\n",
    "    print(f'[{i:02d}] Test accuracy i {accuracy:.3f}')\n",
    "    print(f'[{i:02d}] Features used for splitting are {feat_index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_test[0].reshape(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape of `y_probas` is `n_trees` x `test_size` x `n_classes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas[-1, 0].argmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging\n",
    "\n",
    "Let's average prediction of `n_trees` decision trees on a same test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba_mean = y_probas.mean(axis=0)\n",
    "y_proba_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas_mean[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions (over the last `n_classes` axis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mean = np.argmax(y_proba_mean, axis=1)\n",
    "print(y_pred_mean[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, evaluate such model (ensemble of trees) and compreare it with a performance of a single tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_mean = accuracy_score(y_test, y_pred_mean)\n",
    "print(f'Score of averaged across ensemble is {score_mean * 100 :.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = accuracy_score(y_test, y_probas[0].argmax(axis=1))\n",
    "print(f'Score of a single tree is {score * 100 :.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Random Observations (Samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can introduce randomization in building a tree with sampling objects from train set (bootstrap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_indices(random_state, n_samples):\n",
    "    \"\"\"Return random indices with repetition (bootstrap).\"\"\"\n",
    "    return np.random \\\n",
    "        .RandomState(random_state) \\\n",
    "        .randint(low=0, high=n_samples, size=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_indices(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [2, 19, 25, 44]  # fix a set of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_probas = np.empty((n_trees, ) + y_test.shape + (10, ))\n",
    "y_probas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, state in enumerate(range(n_trees)):\n",
    "    ix = bootstrap_indices(state, X_train.shape[0])\n",
    "    X_train_ = X_train[ix, :][:, features]\n",
    "    y_train_ = y_train[ix]\n",
    "    X_test_ = X_test[:, features]\n",
    "    \n",
    "    model = DecisionTreeClassifier(max_features=4, max_depth=2, random_state=2)\n",
    "    model.fit(X_train_, y_train_)\n",
    "        \n",
    "    y_pred = model.predict(X_test_)\n",
    "    y_probas[i] = model.predict_proba(X_test_)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    feat_index, = np.nonzero(model.feature_importances_)\n",
    "    print(f'[{i:02d}] Test accuracy i {accuracy:.3f}')\n",
    "    print(f'[{i:02d}] Features used for splitting are {feat_index}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average probablities over `n_trees` axis again and make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba_mean = y_probas.mean(axis=0)\n",
    "y_proba_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mean = np.argmax(y_proba_mean, axis=1)\n",
    "print(y_pred_mean[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_mean = accuracy_score(y_test, y_pred_mean)\n",
    "print(f'Score of averaged across ensemble is {score_mean * 100 :.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Approach: Features + Objeservations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "rs = list(range(5))\n",
    "\n",
    "for state in rs:\n",
    "    ind = bootstrap_indices(state, X_train.shape[0])\n",
    "    X_train_, y_train_ = X_train[ind], y_train[ind]\n",
    "    \n",
    "    model = DecisionTreeClassifier(max_features=6, max_depth=2, random_state=state)\n",
    "\n",
    "    model.fit(X_train_, y_train_)    \n",
    "    models.append(model)  # Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_proba_models = []\n",
    "for model in models:\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    predict_proba_models.append(y_pred_proba)\n",
    "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "    print('Accuracy: {:.3f}'.format(accuracy_score(y_test, y_pred)))\n",
    "predict_proba_models = np.array(predict_proba_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_predict_proba = predict_proba_models.mean(axis=0)\n",
    "mean_predict = np.argmax(mean_predict_proba, axis=1)\n",
    "print('Random Forest Accuracy:', accuracy_score(y_test, mean_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=5, max_features=6, max_depth=2, random_state=1) \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reuse random states to build a tree manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = []\n",
    "for m in model.estimators_:\n",
    "    rs.append(m.random_state)\n",
    "print(rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_train_test_accuracy(param_name, param_grid, **params):\n",
    "    \"\"\"Returns train and test perfomance of a RandomForest for\n",
    "    different values (param_grid) of a hyperparameter (param_name).\n",
    "    \"\"\"\n",
    "    \n",
    "    train_score, test_score = [], []\n",
    "    clf = RandomForestClassifier(n_estimators=5, max_features=8, max_depth=6, random_state=1, n_jobs=-1)\n",
    "    if params:\n",
    "        clf.set_params(**params)\n",
    "    \n",
    "    for param_value in tqdm(param_grid):\n",
    "        clf.set_params(**{param_name: param_value})\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        train_score.append(accuracy_score(y_train, clf.predict(X_train)))\n",
    "        test_score.append(accuracy_score(y_test, clf.predict(X_test)))\n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest: Number of Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy, test_accuracy = rf_train_test_accuracy('n_estimators', range(1, 50, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(list(range(1,50,2)), 1-np.array(train_accuracy), label='Train error')\n",
    "plt.plot(list(range(1,50,2)), 1-np.array(test_accuracy), label='Test error')\n",
    "plt.xlabel('Number of trees in the forest')\n",
    "plt.ylabel('Classification error (1 - accuracy).')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest. Tree Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy, test_accuracy = rf_train_test_accuracy('max_depth', range(1, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(list(range(1,30)), 1-np.array(train_accuracy), label='Train error')\n",
    "plt.plot(list(range(1,30)), 1-np.array(test_accuracy), label='Test error')\n",
    "plt.xlabel('Tree depth')\n",
    "plt.ylabel('Classification error (1 - accuracy).')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest: Number of Max Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy, test_accuracy = rf_train_test_accuracy('max_features', range(1, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(list(range(1, 64)), 1-np.array(train_accuracy), label='Train error')\n",
    "plt.plot(list(range(1, 64)), 1-np.array(test_accuracy), label='Test error')\n",
    "plt.xlabel('Max features to consider for split')\n",
    "plt.ylabel('Classification error (1 - accuracy).')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': 20,\n",
    "    'max_depth': 10\n",
    "}\n",
    "train_accuracy, test_accuracy = rf_train_test_accuracy('max_features', range(1, 64), **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(list(range(1, 64)), 1-np.array(train_accuracy), label='Train error')\n",
    "plt.plot(list(range(1, 64)), 1-np.array(test_accuracy), label='Test error')\n",
    "plt.xlabel('Max features to consider for split')\n",
    "plt.ylabel('Classification error (1 - accuracy).')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically something between log2(k) and sqrt(k) will work as a max_features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
