{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classification Algorithm\n",
    "\n",
    "- **Traininig**\n",
    "    1. Find most *informative* combination of `node of the tree`,  `feature`, and  `split value`\n",
    "    2. Do split if `max_depth` is not reached\n",
    "    3. Iterate over 1-2.\n",
    "\n",
    "- **Inference** (prediction)\n",
    "    1. Follow the decision rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Decision Tree Example\n",
    "\n",
    "Let's consider a simple classification: there are 20 balls of blue and yellow colours. Each ball is located in integer points from 0 to 20 (excluded). We want to guess ball colour `y` given its position (integer coordinate `x`).\n",
    "\n",
    "![Visualization of decision tree][1]\n",
    "\n",
    "[1]: ./fancy_tree.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilities\n",
    "\n",
    "(Sample Means)\n",
    "\n",
    "> Before the first split (aka class probabilities)\n",
    "\n",
    "$$\n",
    "    P(y=\\text{BLUE}) = \\frac{9}{20} = 0.45,\n",
    "    \\quad\n",
    "    P(y=\\text{YELLOW}) = \\frac{11}{20} = 0.55.\n",
    "$$\n",
    "\n",
    "> After the first split (aka conditional on coordinate proba)\n",
    "\n",
    "$$\n",
    "    P(y=\\text{BLUE}|X\\leq 12) = \\frac{8}{13} \\approx 0.62,\n",
    "    \\quad\n",
    "    P(y=\\text{BLUE}|X> 12) = \\frac{1}{7} \\approx 0.14.\n",
    "$$\n",
    "\n",
    "$$\n",
    "    P(y=\\text{YELLOW}|X\\leq 12) = \\frac{5}{13} \\approx 0.38, \n",
    "    \\quad\n",
    "    P(y=\\text{YELLOW}|X > 12) = \\frac{6}{7} \\approx 0.86.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Criterion\n",
    "\n",
    "### Entropy\n",
    "\n",
    "$$\n",
    "    H(p) = - \\sum_i^K p_i\\log(p_i)\n",
    "$$\n",
    "\n",
    "\n",
    "> Before the first split\n",
    "\n",
    "$$H = - 0.45 \\log 0.45 - 0.55 \\log 0.55 \\approx -0.69 $$\n",
    "\n",
    "> After the first split\n",
    "\n",
    "$$H_{\\text{left}} = - 0.62 \\log 0.62 - 0.38 \\log 0.38 \\approx -0.66$$\n",
    "\n",
    "$$H_{\\text{right}} = - 0.14 \\log 0.14 - 0.86 \\log 0.86 \\approx -0.40$$\n",
    "\n",
    "$$H_{\\text{total}} =  - \\frac{13}{20} 0.66 - \\frac{7}{20} 0.40 \\approx -0.86$$\n",
    "\n",
    "### Information Gain\n",
    "\n",
    "$$\n",
    "    IG = H(\\text{parent}) - \\sum_{child} H(\\text{child})\n",
    "$$\n",
    "\n",
    "\n",
    "$$IG = -0.69 - (-0.86) = 0.13$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load dataset as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "feats = iris.data\n",
    "labels = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import an algorithm and train its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(feats, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at strucuture of decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.tree import plot_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 5), dpi=150)\n",
    "plot_tree(clf, ax=ax, filled=True, proportion=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(12, 6), dpi=150, layout='constrained')\n",
    "\n",
    "pairs = [[0, 1], [0, 2], [0, 3], [1, 2], [1, 3], [2, 3]]\n",
    "for pairidx, (ax, pair) in enumerate(zip(axs.flatten(), pairs)):\n",
    "    # Train model.\n",
    "    X = iris.data[:, pair]\n",
    "    y = iris.target\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # Plot the decision boundary\n",
    "    DecisionBoundaryDisplay.from_estimator(\n",
    "        clf,\n",
    "        X,\n",
    "        cmap=plt.cm.RdYlBu,\n",
    "        response_method='predict',\n",
    "        ax=ax,\n",
    "        xlabel=iris.feature_names[pair[0]],\n",
    "        ylabel=iris.feature_names[pair[1]],\n",
    "    )\n",
    "\n",
    "    # Plot the training points\n",
    "    for i, color in enumerate('ryb'):\n",
    "        idx = np.where(y == i)\n",
    "        ax.scatter(\n",
    "            X[idx, 0],\n",
    "            X[idx, 1],\n",
    "            c=color,\n",
    "            label=iris.target_names[i],\n",
    "            cmap=plt.cm.RdYlBu,\n",
    "            edgecolor=\"black\",\n",
    "            s=15,\n",
    "        )\n",
    "\n",
    "plt.legend(loc='lower right', borderpad=0, handletextpad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forest Cover Type\n",
    "\n",
    "Read in the data as `pandas.DataFrame`. Download data as CSV files from the [UCI][1] dataset collection then unzip it. There is a corresponding [Kaggle competition][2].\n",
    "\n",
    "[1]: https://archive.ics.uci.edu/dataset/31/covertype\n",
    "[2]: https://www.kaggle.com/c/forest-cover-type-prediction/data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -cq --show-progress https://archive.ics.uci.edu/static/public/31/covertype.zip\n",
    "!unzip -f covertype.zip -d covertype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = [\n",
    "    'Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n",
    "    'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
    "    'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
    "    'Horizontal_Distance_To_Fire_Points'\n",
    "]\n",
    "colnames += [f'Wilderness_Area{i}' for i in range(4)]\n",
    "colnames += [f'Soil_Type{i}' for i in range(40)]\n",
    "colnames += ['Cover_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('covertype/covtype.data.gz', compression='gzip', names=colnames)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.iloc[:15120]\n",
    "df_test = df.iloc[15120:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df_train) == 15120\n",
    "assert len(df_test) == 565892"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the top rows as a train test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('Cover_Type', axis=1),\n",
    "                                                    df.Cover_Type, train_size=.80, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': np.arange(3, 30),\n",
    "    'min_samples_split': np.arange(10, 30, 5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=322)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjust number of jobs (number of trees trained in parallel) to your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_JOBS = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(clf, param_grid=params_grid, cv=cv, n_jobs=N_JOBS, verbose=1)\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot ROC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Public Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit model with best parameters to the whole available dataste (train + val parts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_estimator_.fit(df.drop('Cover_Type', axis=1), df.Cover_Type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load public test test,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then make predictions,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_leaderboard = gs.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and write predictions as a CSV file to local filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(data=y_pred_leaderboard,\n",
    "                           index=test.index, \n",
    "                           columns=['Cover_Type'])\n",
    "predictions.to_csv('decision_tree.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 10 decision_tree.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can submit predictions to kaggle competition but first let's encode hyper-parameters of best model to JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from json import dumps\n",
    "comment = dumps(gs.best_params_)\n",
    "comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo '${comment}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you logged in to kaggle you can submit predictions ([competition][1]).\n",
    "\n",
    "[1]: https://www.kaggle.com/c/forest-cover-type-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit \\\n",
    "    -c forest-cover-type-prediction \\\n",
    "    -f decision_tree.csv \\\n",
    "    -m '${comment}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- All parameters of a `DecisionTreeClassifier` [explained][1].\n",
    "\n",
    "[1]: https://towardsdatascience.com/how-to-tune-a-decision-tree-f03721801680\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
